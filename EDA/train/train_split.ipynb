{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Boston_College_Courses/Thesis/Data/Processed/2010-2014/train/officer_profile.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"/Users/jeremyhudsonchan/Dropbox/Files/Boston_College_Courses/Thesis/Data/Processed/Testing/officer_profile.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['OfficerFirst', 'OfficerLast', 'ApptDate'])\n",
    "test = test.drop(columns = ['OfficerFirst', 'OfficerLast', 'ApptDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['OfficerID', 'Gender', 'Race', 'Rank', 'Age', 'Beat', 'historic_counts',\n",
       "        'prev_allegations', 'new_allegations', 'ApptYear', 'YearsInForce'],\n",
       "       dtype='object'),\n",
       " Index(['OfficerID', 'Gender', 'Race', 'Rank', 'Age', 'Beat', 'historic_counts',\n",
       "        'prev_allegations', 'new_allegations', 'ApptYear', 'YearsInForce'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns, test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50218, 11)\n",
      "(14021, 11)\n"
     ]
    }
   ],
   "source": [
    "# if beat is nan, remove row\n",
    "print(train.shape)\n",
    "train = train.dropna(subset=['Beat'])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50218, 11)\n",
      "(15380, 11)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test = test.dropna(subset=['Beat'])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are nan values, drop the row\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Beat\"] = train[\"Beat\"].astype(int)\n",
    "test[\"Beat\"] = test[\"Beat\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['OfficerID', 'Gender', 'Race', 'Rank', 'Age', 'Beat', 'historic_counts',\n",
       "        'prev_allegations', 'new_allegations', 'ApptYear', 'YearsInForce'],\n",
       "       dtype='object'),\n",
       " Index(['OfficerID', 'Gender', 'Race', 'Rank', 'Age', 'Beat', 'historic_counts',\n",
       "        'prev_allegations', 'new_allegations', 'ApptYear', 'YearsInForce'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns, test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OfficerID Gender           Race             Rank  Age  Beat  \\\n",
      "0          4      M          White  Po As Detective   80   321   \n",
      "1         13      M          White   Police Officer   69  1511   \n",
      "2         17      M          Black   Police Officer   64  2525   \n",
      "3         19      M  Asian/Pacific   Police Officer   73  1122   \n",
      "4         34      M          Black   Police Officer   49  1212   \n",
      "\n",
      "   historic_counts  prev_allegations  new_allegations  ApptYear  YearsInForce  \n",
      "0               71                 2                0    1969.0          41.0  \n",
      "1               75                 2                1    1982.0          28.0  \n",
      "2              260                25                0    1989.0          21.0  \n",
      "3                2                 4                1    1999.0          11.0  \n",
      "4                3                11                1    1998.0          12.0  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name of new_allegation to new_allegations\n",
    "test = test.rename(columns={\"new_allegation\": \"new_allegations\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_allegation is target\n",
    "X_train = train.drop(columns = ['new_allegations'])\n",
    "y_train = train['new_allegations']\n",
    "X_test = test.drop(columns = ['new_allegations'])\n",
    "y_test = test['new_allegations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=2, depth=2, learning_rate=1, loss_function='RMSE', cat_features=['Gender', 'Race', 'Beat', \"Rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3755760\ttotal: 4.81ms\tremaining: 4.81ms\n",
      "1:\tlearn: 2.3183029\ttotal: 7.22ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x144d52e80>"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.96469004,  0.        ,  0.        ,  0.        , 18.05545158,\n",
       "        0.        ,  0.        , 79.97985838,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5206550021558927"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predicited results, compare to actual results\n",
    "y_pred = model.predict(X_test)\n",
    "# round to nearest integer\n",
    "# y_pred = np.round(y_pred)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15269,)\n"
     ]
    }
   ],
   "source": [
    "# make y_pred and y_test into a dataframe\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "actual = pd.DataFrame(y_test)\n",
    "# combine y_pred and y_test into one dataframe\n",
    "predictions = pd.concat([predictions, actual], axis=1)\n",
    "predictions.columns = ['Predicted', 'Actual']\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values\n",
    "predictions = predictions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6470\n",
      "2    4520\n",
      "0    3533\n",
      "3     196\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted\n",
       "0    0.321540\n",
       "1    0.336631\n",
       "2    0.335398\n",
       "3    0.234694\n",
       "Name: Actual, dtype: float64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into 5 bins\n",
    "predictions['Predicted'] = pd.qcut(predictions['Predicted'], 5, labels=False, duplicates = 'drop')\n",
    "print(predictions['Predicted'].value_counts())\n",
    "# calculate mean of actual values in each bin\n",
    "actual_mean = predictions.groupby('Predicted')['Actual'].mean()\n",
    "actual_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.571428571428571"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean squared error of this top 1%\n",
    "mean_absolute_error(top_1['Actual'], top_1['Predicted'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
